

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>OHBM 2021 NiMARE tutorial &#8212; An Introduction to Neuroimaging Meta-Analysis</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'nimare/intro-to-nimare';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="External Meta-Analytic Resources" href="../resources.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../00_intro.html">
  
  
  
  
  
    <p class="title logo__title">An Introduction to Neuroimaging Meta-Analysis</p>
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../00_intro.html">
                    Neuroimaging Meta-Analyses in Python
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Manually curated meta-analysis walkthrough</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../01_overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_planning_and_preparation.html">PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../03_curation.html">Curation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../04_extraction.html">Data extraction/collection from studies</a></li>
<li class="toctree-l1"><a class="reference internal" href="../05_specification.html">Methods to choose from</a></li>
<li class="toctree-l1"><a class="reference internal" href="../06_execution.html">Execution</a></li>
<li class="toctree-l1"><a class="reference internal" href="../07_interpretation.html">interpretation of results</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Deep dives</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../resources.html">External Meta-Analytic Resources</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">OHBM 2021 NiMARE tutorial</a></li>






</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/nimare/intro-to-nimare.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>OHBM 2021 NiMARE tutorial</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">OHBM 2021 NiMARE tutorial</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-nimare">What is NiMARE?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nimare-s-design-philosophy">NiMARE’s design philosophy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stability-and-consistency">Stability and consistency</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#goals-for-this-tutorial">Goals for this tutorial</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#before-we-start-let-s-download-the-necessary-data-only-if-running-locally">Before we start, let’s download the necessary data <strong>only</strong> if running locally</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#basics-of-nimare-datasets">Basics of NiMARE datasets</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#searching-large-datasets">Searching large datasets</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#running-meta-analyses">Running meta-analyses</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#coordinate-based-meta-analysis">Coordinate-based meta-analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multiple-comparisons-correction">Multiple comparisons correction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#image-based-meta-analysis">Image-based meta-analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#compare-to-results-from-the-spm-ibma-extension">Compare to results from the SPM IBMA extension</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#meta-analytic-functional-decoding">Meta-Analytic Functional Decoding</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-run-a-macm-and-decode-an-roi">Exercise: Run a MACM and Decode an ROI</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#after-the-exercise">After the exercise</a></li>
</ul>
</li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <!-- #region -->
<section class="tex2jax_ignore mathjax_ignore" id="ohbm-2021-nimare-tutorial">
<h1>OHBM 2021 NiMARE tutorial<a class="headerlink" href="#ohbm-2021-nimare-tutorial" title="Permalink to this heading">#</a></h1>
<section id="what-is-nimare">
<h2>What is NiMARE?<a class="headerlink" href="#what-is-nimare" title="Permalink to this heading">#</a></h2>
<p><img alt="NiMARE banner" src="nimare/images/nimare_banner.png" /></p>
<p><a class="reference external" href="https://nimare.readthedocs.io/en/latest/">NiMARE</a> is a Python library for performing neuroimaging meta-analyses and related analyses, like automated annotation and functional decoding. The goal of NiMARE is to centralize and standardize implementations of common meta-analytic tools, so that researchers can use whatever tool is most appropriate for a given research question.</p>
<p>There are already a number of tools for neuroimaging meta-analysis:</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p><h2>Tool</h2></p></th>
<th class="head text-left"><p><h2>Scope</h2></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p><a href="https://brainmap.org"><img src="images/brainmap_logo.png" alt="BrainMap" width="400"/></a></p></td>
<td class="text-left"><p>BrainMap includes a suite of applications for (1) searching its manually-annotated coordinate-based database, (2) adding studies to the database, and (3) running ALE meta-analyses. While search results can be extracted using its Sleuth app, access to the full database requires a collaborative use agreement.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><a href="https://brainmap.org"><img src="images/neurosynth_logo.png" alt="Neurosynth" width="200"/></a></p></td>
<td class="text-left"><p>Neurosynth provides (1) a large, automatically-extracted coordinate-based database, (2) a website for performing large-scale automated meta-analyses, and (3) a Python library for performing meta-analyses and functional decoding, mostly relying on a version of the MKDA algorithm. The Python library has been deprecated in favor of <code class="docutils literal notranslate"><span class="pre">NiMARE</span></code>.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><a href="https://www.neurovault.org"><img src="images/neurovault_logo.png" alt="Neurovault" width="200"/></a></p></td>
<td class="text-left"><p>Neurovault is a repository for sharing unthresholded statistical images, which can be used to search for images to use in image-based meta-analyses. Neurovault provides a tool for basic meta-analyses and an integration with Neurosynth’s database for online functional decoding.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><a href="https://www.sdmproject.com"><img src="images/sdm_logo.png" alt="SDM" width="200"/></a></p></td>
<td class="text-left"><p>The Seed-based <em>d</em> Mapping (SDM) app provides a graphical user interface and SPM toolbox for performing meta-analyses with the SDM algorithm, which supports a mix of coordinates and images.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><a href="https://github.com/canlab/Canlab_MKDA_MetaAnalysis"><img src="images/mkda_logo.png" alt="MKDA" width="200"/></a></p></td>
<td class="text-left"><p>The MATLAB-based MKDA toolbox includes functions for performing coordinate-based meta-analyses with the MKDA algorithm.</p></td>
</tr>
</tbody>
</table>
<p>The majority of the above tools are (1) closed source, (2) based on graphical user interfaces, and/or (3) written in a programming language that is rarely used by neuroimagers, such as Java.</p>
<p>In addition to these established tools, there are always interesting new methods that are described in journal articles, but which are never translated to a well-documented and supported implementation.</p>
<p>NiMARE attempts to consolidate the different algorithms that are currently spread out across a range of tools (or which never make the jump from paper to tool), while still ensuring that the original tools and papers can be cited appropriately.</p>
</section>
<section id="nimare-s-design-philosophy">
<h2>NiMARE’s design philosophy<a class="headerlink" href="#nimare-s-design-philosophy" title="Permalink to this heading">#</a></h2>
<p>NiMARE’s API is designed to be similar to that of <a class="reference external" href="https://scikit-learn.org/stable/"><code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code></a>, in that most tools are custom classes. These classes follow the following basic structure:</p>
<ol class="arabic simple">
<li><p>Initialize the class with general parameters</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="bp">cls</span> <span class="o">=</span> <span class="n">Class</span><span class="p">(</span><span class="n">param1</span><span class="p">,</span> <span class="n">param2</span><span class="p">)</span>
</pre></div>
</div>
<ol class="arabic simple" start="2">
<li><p>For Estimator classes, apply a <code class="docutils literal notranslate"><span class="pre">fit</span></code> method to a <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> object to generate a <code class="docutils literal notranslate"><span class="pre">MetaResult</span></code> object</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">result</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
<ol class="arabic simple" start="3">
<li><p>For Transformer classes, apply a <code class="docutils literal notranslate"><span class="pre">transform</span></code> method to an object to return a transformed version of that object</p>
<ul class="simple">
<li><p>An example transformer that accepts a <code class="docutils literal notranslate"><span class="pre">Dataset</span></code>:</p></li>
</ul>
</li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>- A transformer that accepts a `MetaResult`:
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">result</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="stability-and-consistency">
<h2>Stability and consistency<a class="headerlink" href="#stability-and-consistency" title="Permalink to this heading">#</a></h2>
<p>NiMARE is currently in alpha development, so we appreciate any feedback or bug reports users can provide. Given its status, NiMARE’s API may change in the future.</p>
<p>Usage questions can be submitted to <a class="reference external" href="https://neurostars.org/tag/nimare">Neurostars with the ‘nimare’ tag</a>, while bug reports and feature requests can be submitted to <a class="reference external" href="https://github.com/neurostuff/NiMARE/issues">NiMARE’s issue tracker</a>.</p>
<!-- #endregion -->
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="goals-for-this-tutorial">
<h1>Goals for this tutorial<a class="headerlink" href="#goals-for-this-tutorial" title="Permalink to this heading">#</a></h1>
<ol class="arabic simple">
<li><p>Working with NiMARE meta-analytic datasets</p></li>
<li><p>Searching large datasets</p></li>
<li><p>Performing coordinate-based meta-analyses</p></li>
<li><p>Performing image-based meta-analyses</p></li>
<li><p>Performing functional decoding using Neurosynth</p></li>
</ol>
<!-- #region -->
</section>
<section class="tex2jax_ignore mathjax_ignore" id="before-we-start-let-s-download-the-necessary-data-only-if-running-locally">
<h1>Before we start, let’s download the necessary data <strong>only</strong> if running locally<a class="headerlink" href="#before-we-start-let-s-download-the-necessary-data-only-if-running-locally" title="Permalink to this heading">#</a></h1>
<p>The code in the following cell checks whether you have the <a class="reference external" href="https://osf.io/u9sqa/">data</a>, and if you don’t, it starts downloading it.</p>
<p>If you’re running this notebook locally or using mybinder, then you will need to download the data. You can copy the code below into a new cell, with the Jupyter magic command <code class="docutils literal notranslate"><span class="pre">%%bash</span></code> at the top of the cell.</p>
<p>If you’re running it using binder hosted on neurolibre, then you already have access to the data on neurolibre, and you don’t need to run this code snippet.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">DIR</span><span class="o">=</span><span class="s2">$&quot;../data/nimare_tutorial/&quot;</span>
<span class="k">if</span><span class="w"> </span><span class="o">[</span><span class="w"> </span>-d<span class="w"> </span><span class="s2">&quot;</span><span class="nv">$DIR</span><span class="s2">&quot;</span><span class="w"> </span><span class="o">]</span><span class="p">;</span><span class="w"> </span><span class="k">then</span>
<span class="w">    </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;</span><span class="nv">$DIR</span><span class="s2"> exists.&quot;</span>
<span class="k">else</span><span class="w"> </span>
<span class="w">    </span>mkdir<span class="w"> </span>-p<span class="w"> </span><span class="nv">$DIR</span><span class="p">;</span>
<span class="w">    </span>pip<span class="w"> </span>install<span class="w"> </span>osfclient
<span class="w">    </span>osf<span class="w"> </span>-p<span class="w"> </span>u9sqa<span class="w"> </span>clone<span class="w">  </span><span class="nv">$DIR</span><span class="p">;</span>
<span class="w">    </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;Created </span><span class="nv">$DIR</span><span class="s2"> and downloaded the data&quot;</span><span class="p">;</span>
<span class="k">fi</span>
</pre></div>
</div>
<!-- #endregion -->
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import the packages we&#39;ll need for this tutorial</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">os.path</span> <span class="k">as</span> <span class="nn">op</span>
<span class="kn">from</span> <span class="nn">pprint</span> <span class="kn">import</span> <span class="n">pprint</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">nilearn</span> <span class="kn">import</span> <span class="n">plotting</span><span class="p">,</span> <span class="n">reporting</span>

<span class="kn">import</span> <span class="nn">nimare</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">DATA_DIR</span> <span class="o">=</span> <span class="n">op</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="s2">&quot;../data/nimare_tutorial/osfstorage/&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="basics-of-nimare-datasets">
<h1>Basics of NiMARE datasets<a class="headerlink" href="#basics-of-nimare-datasets" title="Permalink to this heading">#</a></h1>
<p>NiMARE relies on a specification for meta-analytic datasets named <a class="reference external" href="https://github.com/neurostuff/NIMADS">NIMADS</a>. Under NIMADS, meta-analytic datasets are stored as JSON files, with information about peak coordinates, <em>relative</em> links to any unthresholded statistical images, metadata, annotations, and raw text.</p>
<p><strong>NOTE</strong>: NiMARE users generally do not need to create JSONs manually, so we won’t go into that structure in this tutorial. Instead, users will typically have access to datasets stored in more established formats, like <a class="reference external" href="https://github.com/neurosynth/neurosynth-data">Neurosynth</a> and <a class="reference external" href="http://brainmap.org/sleuth/">Sleuth</a> files.</p>
<p>We will start by loading a dataset in NIMADS format, because this particular dataset contains both coordinates and images. This dataset is created from <a class="reference external" href="https://identifiers.org/neurovault.collection:1425">Collection 1425 on NeuroVault</a>, which contains <a class="reference external" href="http://nidm.nidash.org/specs/nidm-results_130.html">NIDM-Results packs</a> for 21 pain studies.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pain_dset</span> <span class="o">=</span> <span class="n">nimare</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">Dataset</span><span class="p">(</span><span class="n">op</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span> <span class="s2">&quot;nidm_pain_dset.json&quot;</span><span class="p">))</span>

<span class="c1"># In addition to loading the NIMADS-format JSON file,</span>
<span class="c1"># we need to download the associated statistical images from NeuroVault,</span>
<span class="c1"># for which NiMARE has a useful function.</span>
<span class="n">dset_dir</span> <span class="o">=</span> <span class="n">nimare</span><span class="o">.</span><span class="n">extract</span><span class="o">.</span><span class="n">download_nidm_pain</span><span class="p">(</span><span class="n">data_dir</span><span class="o">=</span><span class="n">DATA_DIR</span><span class="p">)</span>

<span class="c1"># We then notify the Dataset about the location of the images,</span>
<span class="c1"># so that the *relative paths* in the Dataset can be used to determine *absolute paths*.</span>
<span class="n">pain_dset</span><span class="o">.</span><span class="n">update_path</span><span class="p">(</span><span class="n">dset_dir</span><span class="p">)</span>
</pre></div>
</div>
<p>In NiMARE, datasets are stored in a special <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> class. The <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> class stores most relevant information as properties.</p>
<p>The full list of identifiers in the Dataset is located in <code class="docutils literal notranslate"><span class="pre">Dataset.ids</span></code>. Identifiers are composed of two parts- a study ID and a contrast ID. Within the Dataset, those two parts are separated with a <code class="docutils literal notranslate"><span class="pre">-</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">pain_dset</span><span class="o">.</span><span class="n">ids</span><span class="p">)</span>
</pre></div>
</div>
<p>Most other information is stored in <code class="docutils literal notranslate"><span class="pre">pandas</span></code> DataFrames. The five DataFrame-based attributes are <code class="docutils literal notranslate"><span class="pre">Dataset.metadata</span></code>, <code class="docutils literal notranslate"><span class="pre">Dataset.coordinates</span></code>, <code class="docutils literal notranslate"><span class="pre">Dataset.images</span></code>, <code class="docutils literal notranslate"><span class="pre">Dataset.annotations</span></code>, and <code class="docutils literal notranslate"><span class="pre">Dataset.texts</span></code>.</p>
<p>Each DataFrame contains at least three columns: <code class="docutils literal notranslate"><span class="pre">study_id</span></code>, <code class="docutils literal notranslate"><span class="pre">contrast_id</span></code>, and <code class="docutils literal notranslate"><span class="pre">id</span></code>, which is the combined <code class="docutils literal notranslate"><span class="pre">study_id</span></code> and <code class="docutils literal notranslate"><span class="pre">contrast_id</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pain_dset</span><span class="o">.</span><span class="n">coordinates</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pain_dset</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pain_dset</span><span class="o">.</span><span class="n">images</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pain_dset</span><span class="o">.</span><span class="n">annotations</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pain_dset</span><span class="o">.</span><span class="n">texts</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
<p>Other relevant attributes are <code class="docutils literal notranslate"><span class="pre">Dataset.masker</span></code> and <code class="docutils literal notranslate"><span class="pre">Dataset.space</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">Dataset.masker</span></code> is a <a class="reference external" href="https://nilearn.github.io/manipulating_images/masker_objects.html#">nilearn Masker object</a>, which specifies the manner in which voxel-wise information like peak coordinates and statistical images are mapped into usable arrays. Most meta-analytic tools within NiMARE accept a <code class="docutils literal notranslate"><span class="pre">masker</span></code> argument, so the Dataset’s masker can be overridden in most cases.</p>
<p><code class="docutils literal notranslate"><span class="pre">Dataset.space</span></code> is just a string describing the standard space and resolution in which data within the Dataset are stored.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pain_dset</span><span class="o">.</span><span class="n">masker</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pain_dset</span><span class="o">.</span><span class="n">space</span>
</pre></div>
</div>
<!-- #region -->
<p>Datasets can also be saved to, and loaded from, binarized (pickled) files.</p>
<p>We cannot save files on Binder, so here is the code we would use to save the pain Dataset:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pain_dset</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;pain_dataset.pkl.gz&quot;</span><span class="p">)</span>
</pre></div>
</div>
<!-- #endregion -->
<p>Now for a more common situation, where users want to use NiMARE on data from Neurosynth or a Sleuth file.</p>
<!-- #region -->
<p>Downloading and converting the Neurosynth dataset takes a long time, so we will use a pregenerated version of the dataset. However, here is the code we would use to download and convert the dataset from scratch:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">nimare</span><span class="o">.</span><span class="n">extract</span><span class="o">.</span><span class="n">fetch_neurosynth</span><span class="p">(</span><span class="s2">&quot;data/&quot;</span><span class="p">,</span> <span class="n">unpack</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ns_dset</span> <span class="o">=</span> <span class="n">nimare</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">convert_neurosynth_to_dataset</span><span class="p">(</span>
    <span class="s2">&quot;data/database.txt&quot;</span><span class="p">,</span>
    <span class="s2">&quot;data/features.txt&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<!-- #endregion -->
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ns_dset</span> <span class="o">=</span> <span class="n">nimare</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">op</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span> <span class="s2">&quot;neurosynth_dataset.pkl.gz&quot;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;There are </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">ns_dset</span><span class="o">.</span><span class="n">ids</span><span class="p">)</span><span class="si">}</span><span class="s2"> studies in the Neurosynth database.&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">sleuth_dset</span> <span class="o">=</span> <span class="n">nimare</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">convert_sleuth_to_dataset</span><span class="p">(</span><span class="n">op</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span> <span class="s2">&quot;sleuth_dataset.txt&quot;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;There are </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">sleuth_dset</span><span class="o">.</span><span class="n">ids</span><span class="p">)</span><span class="si">}</span><span class="s2"> studies in this dataset.&quot;</span><span class="p">)</span>
</pre></div>
</div>
<section id="searching-large-datasets">
<h2>Searching large datasets<a class="headerlink" href="#searching-large-datasets" title="Permalink to this heading">#</a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> class contains multiple methods for selecting subsets of studies within the dataset.</p>
<p>One common approach is to search by “labels” or “terms” that apply to studies. In Neurosynth, labels are derived from term frequency within abstracts.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">slice</span></code> method creates a reduced <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> from a list of IDs.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pain_ids</span> <span class="o">=</span> <span class="n">ns_dset</span><span class="o">.</span><span class="n">get_studies_by_label</span><span class="p">(</span><span class="s2">&quot;Neurosynth_TFIDF__pain&quot;</span><span class="p">,</span> <span class="n">label_threshold</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>
<span class="n">ns_pain_dset</span> <span class="o">=</span> <span class="n">ns_dset</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="n">pain_ids</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;There are </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">pain_ids</span><span class="p">)</span><span class="si">}</span><span class="s2"> studies labeled with &#39;pain&#39;.&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>A MACM (meta-analytic coactivation modeling) analysis is generally performed by running a meta-analysis on studies with a peak in a region of interest, so Dataset includes two methods for searching based on the locations of coordinates: <code class="docutils literal notranslate"><span class="pre">Dataset.get_studies_by_coordinate</span></code> and <code class="docutils literal notranslate"><span class="pre">Dataset.get_studies_by_mask</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">sphere_ids</span> <span class="o">=</span> <span class="n">ns_dset</span><span class="o">.</span><span class="n">get_studies_by_coordinate</span><span class="p">([[</span><span class="mi">24</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">20</span><span class="p">]],</span> <span class="n">r</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
<span class="n">sphere_dset</span> <span class="o">=</span> <span class="n">ns_dset</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="n">sphere_ids</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;There are </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">sphere_ids</span><span class="p">)</span><span class="si">}</span><span class="s2"> studies with at least one peak within 6mm of [24, -2, -20].&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="running-meta-analyses">
<h1>Running meta-analyses<a class="headerlink" href="#running-meta-analyses" title="Permalink to this heading">#</a></h1>
<section id="coordinate-based-meta-analysis">
<h2>Coordinate-based meta-analysis<a class="headerlink" href="#coordinate-based-meta-analysis" title="Permalink to this heading">#</a></h2>
<p>Most coordinate-based meta-analysis algorithms are kernel-based, in that they convolve peaks reported in papers with a “kernel”. Kernels are generally either binary spheres, as in multi-level kernel density analysis (MKDA), or 3D Gaussian distributions, as in activation likelihood estimation (ALE).</p>
<p>NiMARE includes classes for different kernel transformers, which accept Datasets and generate the images resulting from convolving each study’s peaks with the associated kernel.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a figure</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="c1"># Apply different kernel transformers to the same Dataset</span>
<span class="n">kernels</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">nimare</span><span class="o">.</span><span class="n">meta</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">MKDAKernel</span><span class="p">(</span><span class="n">r</span><span class="o">=</span><span class="mi">10</span><span class="p">),</span>
    <span class="n">nimare</span><span class="o">.</span><span class="n">meta</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">KDAKernel</span><span class="p">(</span><span class="n">r</span><span class="o">=</span><span class="mi">10</span><span class="p">),</span>
    <span class="n">nimare</span><span class="o">.</span><span class="n">meta</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">ALEKernel</span><span class="p">(</span><span class="n">sample_size</span><span class="o">=</span><span class="mi">20</span><span class="p">),</span>
<span class="p">]</span>

<span class="k">for</span> <span class="n">i_kernel</span><span class="p">,</span> <span class="n">kernel</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">kernels</span><span class="p">):</span>
    <span class="n">ma_maps</span> <span class="o">=</span> <span class="n">kernel</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">pain_dset</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s2">&quot;image&quot;</span><span class="p">)</span>

    <span class="c1"># Plot the kernel</span>
    <span class="n">plotting</span><span class="o">.</span><span class="n">plot_stat_map</span><span class="p">(</span>
        <span class="n">ma_maps</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
        <span class="n">annotate</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">axes</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="n">i_kernel</span><span class="p">],</span>
        <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;Reds&quot;</span><span class="p">,</span>
        <span class="n">cut_coords</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">24</span><span class="p">],</span>
        <span class="n">draw_cross</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">figure</span><span class="o">=</span><span class="n">fig</span><span class="p">,</span>
        <span class="n">title</span><span class="o">=</span><span class="nb">type</span><span class="p">(</span><span class="n">kernel</span><span class="p">),</span>
    <span class="p">)</span>

<span class="c1"># Show the overall figure</span>
<span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p>Meta-analytic Estimators are initialized with parameters which determine how the Estimator will be run. For example, ALE accepts a kernel transformer (which defaults to the standard <code class="docutils literal notranslate"><span class="pre">ALEKernel</span></code>), a null method, the number of iterations used to define the null distribution, and the number of cores to be used during fitting.</p>
<p>The Estimators also have a <code class="docutils literal notranslate"><span class="pre">fit</span></code> method, which accepts a <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> object and returns a <code class="docutils literal notranslate"><span class="pre">MetaResult</span></code> object. <a class="reference external" href="https://nimare.readthedocs.io/en/latest/generated/nimare.results.MetaResult.html#nimare.results.MetaResult"><code class="docutils literal notranslate"><span class="pre">MetaResult</span></code>s</a> link statistical image names to numpy arrays, and can be used to produce nibabel images from those arrays, as well as save the images to files.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">meta</span> <span class="o">=</span> <span class="n">nimare</span><span class="o">.</span><span class="n">meta</span><span class="o">.</span><span class="n">cbma</span><span class="o">.</span><span class="n">ale</span><span class="o">.</span><span class="n">ALE</span><span class="p">(</span><span class="n">null_method</span><span class="o">=</span><span class="s2">&quot;approximate&quot;</span><span class="p">)</span>
<span class="n">meta_results</span> <span class="o">=</span> <span class="n">meta</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">pain_dset</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">meta_results</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">meta_results</span><span class="o">.</span><span class="n">maps</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Available maps:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">- &quot;</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n\t</span><span class="s2">- &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">meta_results</span><span class="o">.</span><span class="n">maps</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">z_img</span> <span class="o">=</span> <span class="n">meta_results</span><span class="o">.</span><span class="n">get_map</span><span class="p">(</span><span class="s2">&quot;z&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">z_img</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">plotting</span><span class="o">.</span><span class="n">plot_stat_map</span><span class="p">(</span>
    <span class="n">z_img</span><span class="p">,</span>
    <span class="n">draw_cross</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">cut_coords</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="multiple-comparisons-correction">
<h2>Multiple comparisons correction<a class="headerlink" href="#multiple-comparisons-correction" title="Permalink to this heading">#</a></h2>
<p>Most of the time, you will want to follow up your meta-analysis with some form of multiple comparisons correction. For this, NiMARE provides Corrector classes in the <code class="docutils literal notranslate"><span class="pre">correct</span></code> module. Specifically, there are two Correctors: <a class="reference external" href="https://nimare.readthedocs.io/en/latest/generated/nimare.correct.FWECorrector.html"><code class="docutils literal notranslate"><span class="pre">FWECorrector</span></code></a> and <a class="reference external" href="https://nimare.readthedocs.io/en/latest/generated/nimare.correct.FDRCorrector.html"><code class="docutils literal notranslate"><span class="pre">FDRCorrector</span></code></a>. In both cases, the Corrector supports a range of naive correction options relying on <a class="reference external" href="https://www.statsmodels.org/dev/generated/statsmodels.stats.multitest.multipletests.html"><code class="docutils literal notranslate"><span class="pre">statsmodels</span></code>’ methods</a>.</p>
<p>In addition to generic multiple comparisons correction, the Correctors also reference algorithm-specific correction methods, such as the <code class="docutils literal notranslate"><span class="pre">montecarlo</span></code> method supported by most coordinate-based meta-analysis algorithms.</p>
<p>Correctors are initialized with parameters, and they have a <code class="docutils literal notranslate"><span class="pre">transform</span></code> method that accepts a <code class="docutils literal notranslate"><span class="pre">MetaResult</span></code> object and returns an updated one with the corrected maps.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">mc_corrector</span> <span class="o">=</span> <span class="n">nimare</span><span class="o">.</span><span class="n">correct</span><span class="o">.</span><span class="n">FWECorrector</span><span class="p">(</span>
    <span class="n">method</span><span class="o">=</span><span class="s2">&quot;montecarlo&quot;</span><span class="p">,</span> 
    <span class="n">n_iters</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">n_cores</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">mc_results</span> <span class="o">=</span> <span class="n">mc_corrector</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">meta_results</span><span class="p">)</span>

<span class="c1"># Let&#39;s store the CBMA result for later</span>
<span class="n">cbma_z_img</span> <span class="o">=</span> <span class="n">mc_results</span><span class="o">.</span><span class="n">get_map</span><span class="p">(</span><span class="s2">&quot;z_level-cluster_corr-FWE_method-montecarlo&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">mc_results</span><span class="o">.</span><span class="n">maps</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Available maps:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">- &quot;</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n\t</span><span class="s2">- &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">mc_results</span><span class="o">.</span><span class="n">maps</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">plotting</span><span class="o">.</span><span class="n">plot_stat_map</span><span class="p">(</span>
    <span class="n">mc_results</span><span class="o">.</span><span class="n">get_map</span><span class="p">(</span><span class="s2">&quot;z_level-cluster_corr-FWE_method-montecarlo&quot;</span><span class="p">),</span>
    <span class="n">draw_cross</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">cut_coords</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
    <span class="n">vmax</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Report a standard cluster table for the meta-analytic map using a threshold of p&lt;0.05</span>
<span class="n">reporting</span><span class="o">.</span><span class="n">get_clusters_table</span><span class="p">(</span><span class="n">cbma_z_img</span><span class="p">,</span> <span class="n">stat_threshold</span><span class="o">=</span><span class="mf">1.65</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="image-based-meta-analysis">
<h2>Image-based meta-analysis<a class="headerlink" href="#image-based-meta-analysis" title="Permalink to this heading">#</a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pain_dset</span><span class="o">.</span><span class="n">images</span>
</pre></div>
</div>
<p>Note that “z” images are missing for some, but not all, of the studies.</p>
<p>NiMARE’s <code class="docutils literal notranslate"><span class="pre">transforms</span></code> module contains a class, <code class="docutils literal notranslate"><span class="pre">ImageTransformer</span></code>, which can generate images from other images- as long as the right images and metadata are available. In this case, it can generate z-statistic images from t-statistic maps, combined with sample size information in the metadata. It can also generate “varcope” (contrast variance) images from the contrast standard error images.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Calculate missing images</span>
<span class="n">z_transformer</span> <span class="o">=</span> <span class="n">nimare</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">ImageTransformer</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="s2">&quot;z&quot;</span><span class="p">,</span> <span class="n">overwrite</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">pain_dset</span> <span class="o">=</span> <span class="n">z_transformer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">pain_dset</span><span class="p">)</span>

<span class="n">varcope_transformer</span> <span class="o">=</span> <span class="n">nimare</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">ImageTransformer</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="s2">&quot;varcope&quot;</span><span class="p">,</span> <span class="n">overwrite</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">pain_dset</span> <span class="o">=</span> <span class="n">varcope_transformer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">pain_dset</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pain_dset</span><span class="o">.</span><span class="n">images</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
<p>Now that we have all of the image types we will need for our meta-analyses, we can run a couple of image-based meta-analysis types.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">DerSimonianLaird</span></code> method uses “beta” and “varcope” images, and estimates between-study variance (a.k.a. <span class="math notranslate nohighlight">\(\tau^2\)</span>).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">meta</span> <span class="o">=</span> <span class="n">nimare</span><span class="o">.</span><span class="n">meta</span><span class="o">.</span><span class="n">ibma</span><span class="o">.</span><span class="n">DerSimonianLaird</span><span class="p">()</span>
<span class="n">meta_results</span> <span class="o">=</span> <span class="n">meta</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">pain_dset</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">plotting</span><span class="o">.</span><span class="n">plot_stat_map</span><span class="p">(</span>
    <span class="n">meta_results</span><span class="o">.</span><span class="n">get_map</span><span class="p">(</span><span class="s2">&quot;z&quot;</span><span class="p">),</span>
    <span class="n">draw_cross</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">cut_coords</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<span class="p">)</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">PermutedOLS</span></code> method uses z-statistic images, and relies on <a class="reference external" href="https://nilearn.github.io/modules/generated/nilearn.mass_univariate.permuted_ols.html">nilearn’s <code class="docutils literal notranslate"><span class="pre">permuted_ols</span></code></a> tool.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">meta</span> <span class="o">=</span> <span class="n">nimare</span><span class="o">.</span><span class="n">meta</span><span class="o">.</span><span class="n">ibma</span><span class="o">.</span><span class="n">PermutedOLS</span><span class="p">()</span>
<span class="n">meta_results</span> <span class="o">=</span> <span class="n">meta</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">pain_dset</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">plotting</span><span class="o">.</span><span class="n">plot_stat_map</span><span class="p">(</span>
    <span class="n">meta_results</span><span class="o">.</span><span class="n">get_map</span><span class="p">(</span><span class="s2">&quot;z&quot;</span><span class="p">),</span>
    <span class="n">draw_cross</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">cut_coords</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">mc_corrector</span> <span class="o">=</span> <span class="n">nimare</span><span class="o">.</span><span class="n">correct</span><span class="o">.</span><span class="n">FWECorrector</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s2">&quot;montecarlo&quot;</span><span class="p">,</span> <span class="n">n_iters</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">mc_results</span> <span class="o">=</span> <span class="n">mc_corrector</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">meta_results</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">mc_results</span><span class="o">.</span><span class="n">maps</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Available maps:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">- &quot;</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n\t</span><span class="s2">- &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">mc_results</span><span class="o">.</span><span class="n">maps</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">plotting</span><span class="o">.</span><span class="n">plot_stat_map</span><span class="p">(</span>
    <span class="n">mc_results</span><span class="o">.</span><span class="n">get_map</span><span class="p">(</span><span class="s2">&quot;z_level-voxel_corr-FWE_method-montecarlo&quot;</span><span class="p">),</span>
    <span class="n">draw_cross</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">cut_coords</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
    <span class="n">vmax</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Report a standard cluster table for the meta-analytic map using a threshold of p&lt;0.05</span>
<span class="n">reporting</span><span class="o">.</span><span class="n">get_clusters_table</span><span class="p">(</span>
    <span class="n">mc_results</span><span class="o">.</span><span class="n">get_map</span><span class="p">(</span><span class="s2">&quot;z_level-voxel_corr-FWE_method-montecarlo&quot;</span><span class="p">),</span>
    <span class="n">stat_threshold</span><span class="o">=</span><span class="mf">1.65</span><span class="p">,</span>
    <span class="n">cluster_threshold</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="compare-to-results-from-the-spm-ibma-extension">
<h2>Compare to results from the SPM IBMA extension<a class="headerlink" href="#compare-to-results-from-the-spm-ibma-extension" title="Permalink to this heading">#</a></h2>
<p><img alt="IBMA comparison" src="nimare/images/ibma_comparison.png" /></p>
<p>Adapted from <a class="reference external" href="https://www.frontiersin.org/10.3389/conf.fninf.2014.18.00025/event_abstract">Maumet &amp; Nichols (2014)</a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">plotting</span><span class="o">.</span><span class="n">plot_stat_map</span><span class="p">(</span>
    <span class="n">mc_results</span><span class="o">.</span><span class="n">get_map</span><span class="p">(</span><span class="s2">&quot;z_level-voxel_corr-FWE_method-montecarlo&quot;</span><span class="p">),</span>
    <span class="n">threshold</span><span class="o">=</span><span class="mf">1.65</span><span class="p">,</span>
    <span class="n">vmax</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">draw_cross</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">cut_coords</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">plotting</span><span class="o">.</span><span class="n">plot_stat_map</span><span class="p">(</span>
    <span class="n">cbma_z_img</span><span class="p">,</span>
    <span class="n">threshold</span><span class="o">=</span><span class="mf">1.65</span><span class="p">,</span>
    <span class="n">vmax</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">draw_cross</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">cut_coords</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="meta-analytic-functional-decoding">
<h1>Meta-Analytic Functional Decoding<a class="headerlink" href="#meta-analytic-functional-decoding" title="Permalink to this heading">#</a></h1>
<p>Functional decoding refers to approaches which attempt to infer mental processes, tasks, etc. from imaging data. There are many approaches to functional decoding, but one set of approaches uses meta-analytic databases like Neurosynth or BrainMap, which we call “meta-analytic functional decoding.” For more information on functional decoding in general, read <a class="reference external" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3240863/">Poldrack (2011)</a>.</p>
<p>In NiMARE, we group decoding methods into three general types: discrete decoding, continuous decoding, and encoding.</p>
<ul class="simple">
<li><p><strong>Discrete decoding methods</strong> use a meta-analytic database and annotations of studies in that database to describe something discrete (like a region of interest) in terms of those annotations.</p></li>
<li><p><strong>Continuous decoding methods</strong> use the same type of database to describe an unthresholded brain map in terms of the database’s annotations. One example of this kind of method is the Neurosynth-based decoding available on Neurovault. In that method, the map you want to decode is correlated with Neurosynth term-specific meta-analysis maps. You end up with one correlation coefficient for each term in Neurosynth. Users generally report the top ten or so terms.</p></li>
<li><p><strong>Encoding methods</strong> do the opposite- they take in annotations or raw text and produce a synthesized brain map. One example of a meta-analytic encoding tool is <a class="reference external" href="https://neuroquery.org/">NeuroQuery</a>.</p></li>
</ul>
<p>Most of the continuous decoding methods available in NiMARE are too computationally intensive and time-consuming for Binder, so we will focus on discrete decoding methods.
The two most useful discrete decoders in NiMARE are the <a class="reference external" href="https://nimare.readthedocs.io/en/latest/generated/nimare.decode.discrete.BrainMapDecoder.html#nimare.decode.discrete.BrainMapDecoder"><code class="docutils literal notranslate"><span class="pre">BrainMapDecoder</span></code></a> and the <a class="reference external" href="https://nimare.readthedocs.io/en/latest/generated/nimare.decode.discrete.NeurosynthDecoder.html#nimare.decode.discrete.NeurosynthDecoder"><code class="docutils literal notranslate"><span class="pre">NeurosynthDecoder</span></code></a>. Detailed descriptions of the two approaches are available in <a class="reference external" href="https://nimare.readthedocs.io/en/latest/methods/decoding.html#discrete-decoding">NiMARE’s documentation</a>, but here’s the basic idea:</p>
<ol class="arabic simple" start="0">
<li><p>A NiMARE <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> must contain both annotations/labels and coordinates.</p></li>
<li><p>A subset of studies in the <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> must be selected according to some criterion, such as having at least one peak in a region of interest or having a specific label.</p></li>
<li><p>The algorithm then compares the frequency of each label within the selected subset of studies against the frequency of other labels in that subset to calculate “forward-inference” posterior probability, p-value, and z-statistic.</p></li>
<li><p>The algorithm also compares the frequency of each label within the subset of studies against the the frequency of that label in the <em>unselected</em> studies from the <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> to calculate “reverse-inference” posterior probability, p-value, and z-statistic.</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Given the sheer size of Neurosynth, we will only use the first 500 studies in this example</span>
<span class="n">ns_dset</span> <span class="o">=</span> <span class="n">ns_dset</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="n">ns_dset</span><span class="o">.</span><span class="n">ids</span><span class="p">[:</span><span class="mi">500</span><span class="p">])</span>

<span class="n">label_ids</span> <span class="o">=</span> <span class="n">ns_dset</span><span class="o">.</span><span class="n">get_studies_by_label</span><span class="p">(</span><span class="s2">&quot;Neurosynth_TFIDF__amygdala&quot;</span><span class="p">,</span> <span class="n">label_threshold</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;There are </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">label_ids</span><span class="p">)</span><span class="si">}</span><span class="s2"> studies in the Dataset with the &#39;Neurosynth_TFIDF__amygdala&#39; label.&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">decoder</span> <span class="o">=</span> <span class="n">nimare</span><span class="o">.</span><span class="n">decode</span><span class="o">.</span><span class="n">discrete</span><span class="o">.</span><span class="n">BrainMapDecoder</span><span class="p">(</span><span class="n">correction</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">decoder</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">ns_dset</span><span class="p">)</span>
<span class="n">decoded_df</span> <span class="o">=</span> <span class="n">decoder</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">ids</span><span class="o">=</span><span class="n">label_ids</span><span class="p">)</span>
<span class="n">decoded_df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s2">&quot;probReverse&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">decoder</span> <span class="o">=</span> <span class="n">nimare</span><span class="o">.</span><span class="n">decode</span><span class="o">.</span><span class="n">discrete</span><span class="o">.</span><span class="n">NeurosynthDecoder</span><span class="p">(</span><span class="n">correction</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">decoder</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">ns_dset</span><span class="p">)</span>
<span class="n">decoded_df</span> <span class="o">=</span> <span class="n">decoder</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">ids</span><span class="o">=</span><span class="n">label_ids</span><span class="p">)</span>
<span class="n">decoded_df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s2">&quot;probReverse&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="exercise-run-a-macm-and-decode-an-roi">
<h1>Exercise: Run a MACM and Decode an ROI<a class="headerlink" href="#exercise-run-a-macm-and-decode-an-roi" title="Permalink to this heading">#</a></h1>
<p>Remember that a MACM is a meta-analysis performed on studies which report at least one peak within a region of interest. This type of analysis is generally interpreted as a meta-analytic version of functional connectivity analysis.</p>
<p>We will use an amygdala mask as our ROI, which we will use to (1) run a MACM using the (reduced) Neurosynth dataset and (2) decode the ROI using labels from Neurosynth.</p>
<p>First, we have to prepare some things for the exercise. You just need to run these cells without editing anything.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ROI_FILE</span> <span class="o">=</span> <span class="n">op</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span> <span class="s2">&quot;amygdala_roi.nii.gz&quot;</span><span class="p">)</span>

<span class="n">plotting</span><span class="o">.</span><span class="n">plot_roi</span><span class="p">(</span>
    <span class="n">ROI_FILE</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Right Amygdala&quot;</span><span class="p">,</span>
    <span class="n">draw_cross</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Below, try to write code in each cell based on its comment.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># First, use the Dataset class&#39;s get_studies_by_mask method</span>
<span class="c1"># to identify studies with at least one coordinate in the ROI.</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Now, create a reduced version of the Dataset including only</span>
<span class="c1"># studies identified above.</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Next, run a meta-analysis on the reduced ROI dataset.</span>
<span class="c1"># This is a MACM.</span>
<span class="c1"># Use the nimare.meta.cbma.MKDADensity meta-analytic estimator.</span>
<span class="c1"># Do not perform multiple comparisons correction.</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Initialize, fit, and transform a Neurosynth Decoder.</span>
</pre></div>
</div>
<section id="after-the-exercise">
<h2>After the exercise<a class="headerlink" href="#after-the-exercise" title="Permalink to this heading">#</a></h2>
<p>Your MACM results should look something like this:</p>
<p><img alt="MACM Results" src="nimare/images/macm_result.png" /></p>
<p>And your decoding results should look something like this, after sorting by probReverse:</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Term</p></th>
<th class="head text-right"><p>pForward</p></th>
<th class="head text-right"><p>zForward</p></th>
<th class="head text-right"><p>probForward</p></th>
<th class="head text-right"><p>pReverse</p></th>
<th class="head text-right"><p>zReverse</p></th>
<th class="head text-right"><p>probReverse</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p>Neurosynth_TFIDF__amygdala</p></td>
<td class="text-right"><p>4.14379e-113</p></td>
<td class="text-right"><p>22.602</p></td>
<td class="text-right"><p>0.2455</p></td>
<td class="text-right"><p>1.17242e-30</p></td>
<td class="text-right"><p>11.5102</p></td>
<td class="text-right"><p>0.964733</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>Neurosynth_TFIDF__reinforcement</p></td>
<td class="text-right"><p>7.71236e-05</p></td>
<td class="text-right"><p>3.95317</p></td>
<td class="text-right"><p>0.522177</p></td>
<td class="text-right"><p>7.35753e-15</p></td>
<td class="text-right"><p>7.77818</p></td>
<td class="text-right"><p>0.957529</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>Neurosynth_TFIDF__olfactory</p></td>
<td class="text-right"><p>0.0147123</p></td>
<td class="text-right"><p>2.43938</p></td>
<td class="text-right"><p>0.523139</p></td>
<td class="text-right"><p>5.84089e-11</p></td>
<td class="text-right"><p>6.54775</p></td>
<td class="text-right"><p>0.955769</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>Neurosynth_TFIDF__fear</p></td>
<td class="text-right"><p>1.52214e-11</p></td>
<td class="text-right"><p>6.74577</p></td>
<td class="text-right"><p>0.448855</p></td>
<td class="text-right"><p>6.41482e-19</p></td>
<td class="text-right"><p>8.88461</p></td>
<td class="text-right"><p>0.95481</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>Neurosynth_TFIDF__age sex</p></td>
<td class="text-right"><p>0.503406</p></td>
<td class="text-right"><p>0.669141</p></td>
<td class="text-right"><p>0.524096</p></td>
<td class="text-right"><p>3.8618e-07</p></td>
<td class="text-right"><p>5.07565</p></td>
<td class="text-right"><p>0.954023</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>Neurosynth_TFIDF__appraisal</p></td>
<td class="text-right"><p>0.503406</p></td>
<td class="text-right"><p>0.669141</p></td>
<td class="text-right"><p>0.524096</p></td>
<td class="text-right"><p>3.8618e-07</p></td>
<td class="text-right"><p>5.07565</p></td>
<td class="text-right"><p>0.954023</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>Neurosynth_TFIDF__apart</p></td>
<td class="text-right"><p>0.503406</p></td>
<td class="text-right"><p>0.669141</p></td>
<td class="text-right"><p>0.524096</p></td>
<td class="text-right"><p>3.8618e-07</p></td>
<td class="text-right"><p>5.07565</p></td>
<td class="text-right"><p>0.954023</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>Neurosynth_TFIDF__naturalistic</p></td>
<td class="text-right"><p>0.555471</p></td>
<td class="text-right"><p>0.589582</p></td>
<td class="text-right"><p>0.52505</p></td>
<td class="text-right"><p>0.00122738</p></td>
<td class="text-right"><p>3.23244</p></td>
<td class="text-right"><p>0.95229</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>Neurosynth_TFIDF__controls hc</p></td>
<td class="text-right"><p>0.555471</p></td>
<td class="text-right"><p>0.589582</p></td>
<td class="text-right"><p>0.52505</p></td>
<td class="text-right"><p>0.00122738</p></td>
<td class="text-right"><p>3.23244</p></td>
<td class="text-right"><p>0.95229</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>Neurosynth_TFIDF__morphology</p></td>
<td class="text-right"><p>0.555471</p></td>
<td class="text-right"><p>0.589582</p></td>
<td class="text-right"><p>0.52505</p></td>
<td class="text-right"><p>0.00122738</p></td>
<td class="text-right"><p>3.23244</p></td>
<td class="text-right"><p>0.95229</p></td>
</tr>
</tbody>
</table>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./nimare"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="../resources.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">External Meta-Analytic Resources</p>
      </div>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">OHBM 2021 NiMARE tutorial</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-nimare">What is NiMARE?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nimare-s-design-philosophy">NiMARE’s design philosophy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stability-and-consistency">Stability and consistency</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#goals-for-this-tutorial">Goals for this tutorial</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#before-we-start-let-s-download-the-necessary-data-only-if-running-locally">Before we start, let’s download the necessary data <strong>only</strong> if running locally</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#basics-of-nimare-datasets">Basics of NiMARE datasets</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#searching-large-datasets">Searching large datasets</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#running-meta-analyses">Running meta-analyses</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#coordinate-based-meta-analysis">Coordinate-based meta-analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multiple-comparisons-correction">Multiple comparisons correction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#image-based-meta-analysis">Image-based meta-analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#compare-to-results-from-the-spm-ibma-extension">Compare to results from the SPM IBMA extension</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#meta-analytic-functional-decoding">Meta-Analytic Functional Decoding</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-run-a-macm-and-decode-an-roi">Exercise: Run a MACM and Decode an ROI</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#after-the-exercise">After the exercise</a></li>
</ul>
</li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The Neurostuff Team
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>